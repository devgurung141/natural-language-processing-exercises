{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1694907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bc0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"The price of a domestic 14.2 kg-LPG cylinder has been increased by \\u20b950/unit and it will now cost \\\n",
    "\\u20b91,103/unit in Delhi. The price of a commercial 19 kg-LPG cylinder has also been hiked by \\u20b9350.50/unit, \\\n",
    "raising the cost to \\u20b92,119.50/unit in the national capital. This is the second time the price of commercial LPG\\\n",
    "cylinders has been hiked this year.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f1920",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0702ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    original = original.lower()\n",
    "    original = unicodedata.normalize('NFKD', original).encode('ascii', 'ignore').decode('utf-8')\n",
    "    original = re.sub(r'[^a-z0-9\\s]', '', original)\n",
    "    return original\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70c2c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the price of a domestic 142 kglpg cylinder has been increased by 50unit and it will now cost 1103unit in delhi the price of a commercial 19 kglpg cylinder has also been hiked by 35050unit raising the cost to 211950unit in the national capital this is the second time the price of commercial lpgcylinders has been hiked this year'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = basic_clean(original)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef17e7",
   "metadata": {},
   "source": [
    "#### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be6f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(original):\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    original = tokenize.tokenize(original)\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc04499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'a',\n",
       " 'domestic',\n",
       " '142',\n",
       " 'kglpg',\n",
       " 'cylinder',\n",
       " 'has',\n",
       " 'been',\n",
       " 'increased',\n",
       " 'by',\n",
       " '50unit',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'now',\n",
       " 'cost',\n",
       " '1103unit',\n",
       " 'in',\n",
       " 'delhi',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'a',\n",
       " 'commercial',\n",
       " '19',\n",
       " 'kglpg',\n",
       " 'cylinder',\n",
       " 'has',\n",
       " 'also',\n",
       " 'been',\n",
       " 'hiked',\n",
       " 'by',\n",
       " '35050unit',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'cost',\n",
       " 'to',\n",
       " '211950unit',\n",
       " 'in',\n",
       " 'the',\n",
       " 'national',\n",
       " 'capital',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'time',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'commercial',\n",
       " 'lpgcylinders',\n",
       " 'has',\n",
       " 'been',\n",
       " 'hiked',\n",
       " 'this',\n",
       " 'year']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenize(cleaned)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f91fa",
   "metadata": {},
   "source": [
    "#### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a294c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(original):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stem = [ps.stem(word) for word in original]\n",
    "    return ''.join(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278d5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the price of a domestic 142 kglpg cylinder has been increased by 50unit and it will now cost 1103unit in delhi the price of a commercial 19 kglpg cylinder has also been hiked by 35050unit raising the cost to 211950unit in the national capital this is the second time the price of commercial lpgcylinders has been hiked this year'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeadd20",
   "metadata": {},
   "source": [
    "#### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6311b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(original):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word)for word in original]\n",
    "    return ''.join(lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d0c091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the price of a domestic 142 kglpg cylinder has been increased by 50unit and it will now cost 1103unit in delhi the price of a commercial 19 kglpg cylinder has also been hiked by 35050unit raising the cost to 211950unit in the national capital this is the second time the price of commercial lpgcylinders has been hiked this year'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d227c6",
   "metadata": {},
   "source": [
    "#### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de350cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(original, extra_words=[], exclude_words=[]):\n",
    "    stopword_list = stopwords.words('english')\n",
    "#     stopword_list.remove('the') # takes in one at time\n",
    "#     stopword_list.append('jpt') \n",
    "#     stopword_list.extend(['jpt','sd']) \n",
    "    filtered_words = [w for w in original.split()if w not in stopword_list]\n",
    "    return filtered_words\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3a17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword_list = stopwords.words('english')\n",
    "# stopword_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ecd59b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'domestic',\n",
       " '142',\n",
       " 'kglpg',\n",
       " 'cylinder',\n",
       " 'increased',\n",
       " '50unit',\n",
       " 'cost',\n",
       " '1103unit',\n",
       " 'delhi',\n",
       " 'price',\n",
       " 'commercial',\n",
       " '19',\n",
       " 'kglpg',\n",
       " 'cylinder',\n",
       " 'also',\n",
       " 'hiked',\n",
       " '35050unit',\n",
       " 'raising',\n",
       " 'cost',\n",
       " '211950unit',\n",
       " 'national',\n",
       " 'capital',\n",
       " 'second',\n",
       " 'time',\n",
       " 'price',\n",
       " 'commercial',\n",
       " 'lpgcylinders',\n",
       " 'hiked',\n",
       " 'year']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7437ac",
   "metadata": {},
   "source": [
    "#### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df0b532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(acquire.get_news_articles(['business', 'sports', 'technology', 'entertainment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a384221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>All Adani stocks end higher for the first time...</td>\n",
       "      <td>All 10 Adani Group stocks closed higher on Wed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Bill Gates meets Ratan Tata, N Chandrasekaran;...</td>\n",
       "      <td>Microsoft Co-founder Bill Gates met with Tata ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>SoftBank sells shares worth ₹954 crore in logi...</td>\n",
       "      <td>SoftBank sold shares worth ₹954 crore in logis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Smriti Irani's 2011 tweet on LPG price hike re...</td>\n",
       "      <td>Hours after the central government raised the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Indian-Americans Renjen, Subramaniam to be mem...</td>\n",
       "      <td>Indian-Americans Punit Renjen and Rajesh Subra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              title  \\\n",
       "0  business  All Adani stocks end higher for the first time...   \n",
       "1  business  Bill Gates meets Ratan Tata, N Chandrasekaran;...   \n",
       "2  business  SoftBank sells shares worth ₹954 crore in logi...   \n",
       "3  business  Smriti Irani's 2011 tweet on LPG price hike re...   \n",
       "4  business  Indian-Americans Renjen, Subramaniam to be mem...   \n",
       "\n",
       "                                             content  \n",
       "0  All 10 Adani Group stocks closed higher on Wed...  \n",
       "1  Microsoft Co-founder Bill Gates met with Tata ...  \n",
       "2  SoftBank sold shares worth ₹954 crore in logis...  \n",
       "3  Hours after the central government raised the ...  \n",
       "4  Indian-Americans Punit Renjen and Rajesh Subra...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacece8",
   "metadata": {},
   "source": [
    "#### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086d3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = pd.DataFrame(acquire.get_blog_articles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61291b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>\\nIf you’re interested in embarking on a caree...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "\n",
       "                                             content  \n",
       "0  \\nBlack excellence in tech: Panelist Spotlight...  \n",
       "1  \\nBlack excellence in tech: Panelist Spotlight...  \n",
       "2  \\nBlack excellence in tech: Panelist Spotlight...  \n",
       "3  \\nBlack excellence in tech: Panelist Spotlight...  \n",
       "4  \\nIf you’re interested in embarking on a caree...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22f476",
   "metadata": {},
   "source": [
    "#### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "stemmed to hold the stemmed version of the cleaned data.\n",
    "lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d2c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a10e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df['clean'] = codeup_df['original'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c609cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df['stemmed'] = codeup_df['clean'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c975bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df['lemmatized'] = codeup_df['clean'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9314662b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>\\nBlack excellence in tech: Panelist Spotlight...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "      <td>\\nblack excellence in tech panelist spotlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>\\nIf you’re interested in embarking on a caree...</td>\n",
       "      <td>\\nif youre interested in embarking on a career...</td>\n",
       "      <td>\\nif youre interested in embarking on a career...</td>\n",
       "      <td>\\nif youre interested in embarking on a career...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "\n",
       "                                            original  \\\n",
       "0  \\nBlack excellence in tech: Panelist Spotlight...   \n",
       "1  \\nBlack excellence in tech: Panelist Spotlight...   \n",
       "2  \\nBlack excellence in tech: Panelist Spotlight...   \n",
       "3  \\nBlack excellence in tech: Panelist Spotlight...   \n",
       "4  \\nIf you’re interested in embarking on a caree...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  \\nblack excellence in tech panelist spotlight ...   \n",
       "1  \\nblack excellence in tech panelist spotlight ...   \n",
       "2  \\nblack excellence in tech panelist spotlight ...   \n",
       "3  \\nblack excellence in tech panelist spotlight ...   \n",
       "4  \\nif youre interested in embarking on a career...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  \\nblack excellence in tech panelist spotlight ...   \n",
       "1  \\nblack excellence in tech panelist spotlight ...   \n",
       "2  \\nblack excellence in tech panelist spotlight ...   \n",
       "3  \\nblack excellence in tech panelist spotlight ...   \n",
       "4  \\nif youre interested in embarking on a career...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  \\nblack excellence in tech panelist spotlight ...  \n",
       "1  \\nblack excellence in tech panelist spotlight ...  \n",
       "2  \\nblack excellence in tech panelist spotlight ...  \n",
       "3  \\nblack excellence in tech panelist spotlight ...  \n",
       "4  \\nif youre interested in embarking on a career...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d9f931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e12cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['clean'] = news_df['original'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0c33860",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['stemmed'] = news_df['clean'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d45d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['lemmatized'] = news_df['clean'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef9d5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>All Adani stocks end higher for the first time...</td>\n",
       "      <td>All 10 Adani Group stocks closed higher on Wed...</td>\n",
       "      <td>all 10 adani group stocks closed higher on wed...</td>\n",
       "      <td>all 10 adani group stocks closed higher on wed...</td>\n",
       "      <td>all 10 adani group stocks closed higher on wed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Bill Gates meets Ratan Tata, N Chandrasekaran;...</td>\n",
       "      <td>Microsoft Co-founder Bill Gates met with Tata ...</td>\n",
       "      <td>microsoft cofounder bill gates met with tata s...</td>\n",
       "      <td>microsoft cofounder bill gates met with tata s...</td>\n",
       "      <td>microsoft cofounder bill gates met with tata s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>SoftBank sells shares worth ₹954 crore in logi...</td>\n",
       "      <td>SoftBank sold shares worth ₹954 crore in logis...</td>\n",
       "      <td>softbank sold shares worth 954 crore in logist...</td>\n",
       "      <td>softbank sold shares worth 954 crore in logist...</td>\n",
       "      <td>softbank sold shares worth 954 crore in logist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Smriti Irani's 2011 tweet on LPG price hike re...</td>\n",
       "      <td>Hours after the central government raised the ...</td>\n",
       "      <td>hours after the central government raised the ...</td>\n",
       "      <td>hours after the central government raised the ...</td>\n",
       "      <td>hours after the central government raised the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Indian-Americans Renjen, Subramaniam to be mem...</td>\n",
       "      <td>Indian-Americans Punit Renjen and Rajesh Subra...</td>\n",
       "      <td>indianamericans punit renjen and rajesh subram...</td>\n",
       "      <td>indianamericans punit renjen and rajesh subram...</td>\n",
       "      <td>indianamericans punit renjen and rajesh subram...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              title  \\\n",
       "0  business  All Adani stocks end higher for the first time...   \n",
       "1  business  Bill Gates meets Ratan Tata, N Chandrasekaran;...   \n",
       "2  business  SoftBank sells shares worth ₹954 crore in logi...   \n",
       "3  business  Smriti Irani's 2011 tweet on LPG price hike re...   \n",
       "4  business  Indian-Americans Renjen, Subramaniam to be mem...   \n",
       "\n",
       "                                            original  \\\n",
       "0  All 10 Adani Group stocks closed higher on Wed...   \n",
       "1  Microsoft Co-founder Bill Gates met with Tata ...   \n",
       "2  SoftBank sold shares worth ₹954 crore in logis...   \n",
       "3  Hours after the central government raised the ...   \n",
       "4  Indian-Americans Punit Renjen and Rajesh Subra...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  all 10 adani group stocks closed higher on wed...   \n",
       "1  microsoft cofounder bill gates met with tata s...   \n",
       "2  softbank sold shares worth 954 crore in logist...   \n",
       "3  hours after the central government raised the ...   \n",
       "4  indianamericans punit renjen and rajesh subram...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  all 10 adani group stocks closed higher on wed...   \n",
       "1  microsoft cofounder bill gates met with tata s...   \n",
       "2  softbank sold shares worth 954 crore in logist...   \n",
       "3  hours after the central government raised the ...   \n",
       "4  indianamericans punit renjen and rajesh subram...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  all 10 adani group stocks closed higher on wed...  \n",
       "1  microsoft cofounder bill gates met with tata s...  \n",
       "2  softbank sold shares worth 954 crore in logist...  \n",
       "3  hours after the central government raised the ...  \n",
       "4  indianamericans punit renjen and rajesh subram...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe5773",
   "metadata": {},
   "source": [
    "#### 9. Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e32ba",
   "metadata": {},
   "source": [
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f0e9e",
   "metadata": {},
   "source": [
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ef47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
